{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87e2c492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Config (edit these)\n",
    "# ========================\n",
    "GRAD_BASE_DIR   = \"/pscratch/sd/l/lsx/yyt_tmp/Qwen_Qwen2.5-0.5B-tatsu-lab_alpaca/grad_dump\"\n",
    "WEIGHT_ROOT     = \"/pscratch/sd/l/lsx/yyt_tmp/Qwen_Qwen2.5-0.5B-tatsu-lab_alpaca/weight_dump\"\n",
    "GLOBAL_STEP     = 200        # plots grads @ this step; compares stepXXXXXX_pre vs stepXXXXXX_post\n",
    "OUT_DIR         = \"/pscratch/sd/l/lsx/yyt_tmp/Qwen_Qwen2.5-0.5B-tatsu-lab_alpaca/plots\"\n",
    "\n",
    "SAMPLE_FRAC     = 1.0        # <1.0 to uniformly subsample to save RAM (e.g., 0.25)\n",
    "TOP_P           = 0.01       # annotate top 1% capture on each curve\n",
    "\n",
    "\n",
    "# Optional parameter-name filters for weight delta (regex). Keep None to include all weights.\n",
    "# INCLUDE_PATTERNS = None      # e.g., [r\"self_attn\\\\..*\\\\.weight\", r\"mlp\\\\..*\\\\.weight\"]\n",
    "# EXCLUDE_PATTERNS = None      # e.g., [r\"lm_head\", r\"embed\"]\n",
    "INCLUDE_PATTERNS = [\n",
    "    r\"\\.layers\\.\\d+\\.self_attn\\.(q_proj|k_proj|v_proj|o_proj|qkv|qkv_proj)\\.(weight|bias)$\",\n",
    "    r\"\\.layers\\.\\d+\\.mlp\\.(gate_proj|up_proj|down_proj)\\.(weight|bias)$\",\n",
    "]\n",
    "EXCLUDE_PATTERNS = [\n",
    "    r\"embed|lm_head|norm|layer_norm|ln|rope|rotary|position|alibi\"\n",
    "]\n",
    "INCLUDE_BIAS     = True     # set True to include *.bias in Î”W\n",
    "\n",
    "# ========================\n",
    "# Script\n",
    "# ========================\n",
    "import os, re, gc, math, warnings, glob\n",
    "from typing import Optional, List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Optional safetensors support\n",
    "try:\n",
    "    from safetensors.torch import load_file as safetensors_load\n",
    "    _HAVE_SAFETENSORS = True\n",
    "except Exception:\n",
    "    _HAVE_SAFETENSORS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da829db",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "def _load_any_tensor(path: str) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Load a tensor from path (supports torch .pt/.pth/.bin and numpy .npy/.npz).\n",
    "    Returns CPU float32 tensor.\n",
    "    \"\"\"\n",
    "    ext = os.path.splitext(path)[1].lower()\n",
    "    try:\n",
    "        if ext in [\".pt\", \".pth\", \".bin\"]:\n",
    "            obj = torch.load(path, map_location=\"cpu\")\n",
    "            if isinstance(obj, torch.Tensor):\n",
    "                t = obj\n",
    "            elif isinstance(obj, dict) and \"tensor\" in obj:\n",
    "                t = obj[\"tensor\"]\n",
    "            else:\n",
    "                if isinstance(obj, dict):\n",
    "                    t = None\n",
    "                    for v in obj.values():\n",
    "                        if isinstance(v, torch.Tensor):\n",
    "                            t = v; break\n",
    "                    if t is None:\n",
    "                        raise ValueError(f\"No tensor found in {path}\")\n",
    "                else:\n",
    "                    raise ValueError(f\"Unsupported torch object in {path}: {type(obj)}\")\n",
    "            return t.detach().to(dtype=torch.float32, device=\"cpu\")\n",
    "        elif ext == \".npy\":\n",
    "            arr = np.load(path, allow_pickle=False)\n",
    "            return torch.from_numpy(np.array(arr, dtype=np.float32))\n",
    "        elif ext == \".npz\":\n",
    "            npz = np.load(path, allow_pickle=False)\n",
    "            key = list(npz.keys())[0]\n",
    "            return torch.from_numpy(np.array(npz[key], dtype=np.float32))\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file extension: {ext}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to load tensor from {path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7f21db",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "def _tensor_to_sampled_sq_1d(t: torch.Tensor, sample_frac: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Flatten -> optional uniform subsample -> return squared magnitudes as numpy (x^2).\n",
    "    \"\"\"\n",
    "    t = t.reshape(-1)\n",
    "    if sample_frac < 1.0:\n",
    "        n = t.numel()\n",
    "        k = max(1, int(math.ceil(n * sample_frac)))\n",
    "        idx = torch.randperm(n)[:k]\n",
    "        t = t[idx]\n",
    "    sq = (t**2).to(torch.float32).cpu().numpy()\n",
    "    del t\n",
    "    return sq\n",
    "\n",
    "def _make_curve(values_sq: np.ndarray):\n",
    "    \"\"\"\n",
    "    Given squared magnitudes, build Lorenz-style cumulative curve.\n",
    "    Returns x (proportion), y (cumulative energy), N (count).\n",
    "    \"\"\"\n",
    "    order = np.argsort(values_sq)[::-1]\n",
    "    s = values_sq[order]\n",
    "    N = s.size\n",
    "    x = (np.arange(1, N + 1, dtype=np.float64)) / float(N)\n",
    "    cum = np.cumsum(s, dtype=np.float64)\n",
    "    y = cum / cum[-1]\n",
    "    return x, y, N\n",
    "\n",
    "def _plot_curve(x, y, label, save_path, top_p=0.01, figsize=(5.0, 4.0), dpi=200):\n",
    "    k = max(1, int(math.ceil(top_p * y.size)))\n",
    "    y_top = y[k - 1]\n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n",
    "    ax.plot(x, y, linewidth=2)\n",
    "    ax.axvline(top_p, linestyle=\"--\", linewidth=1.5)\n",
    "    ax.axhline(y_top, linestyle=\"--\", linewidth=1.5)\n",
    "    ax.set_xlabel(\"Proportion of Elements\", fontsize=12)\n",
    "    ax.set_ylabel(\"Cumulative L2 Norm\\u00b2\", fontsize=12)\n",
    "    ax.set_xlim(0.0, 1.0)\n",
    "    ax.set_ylim(0.0, 1.0)\n",
    "    ax.grid(False)\n",
    "    ax.legend([label], loc=\"lower right\", frameon=True)\n",
    "    ax.text(top_p + 0.002, min(0.98, y_top + 0.02),\n",
    "            f\"Top {int(top_p*100)}%\\n{y_top*100:.1f}% of L2\\u00b2\",\n",
    "            fontsize=10, bbox=dict(facecolor=\"white\", alpha=0.8, edgecolor=\"none\"))\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    return float(y_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9999420e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def load_grad_sq_from_index(grad_base_dir: str, global_step: int, sample_frac: float = 1.0,\n",
    "                            index_csv: Optional[str] = None) -> np.ndarray:\n",
    "    if index_csv is None:\n",
    "        index_csv = os.path.join(grad_base_dir, \"index.csv\")\n",
    "    if not os.path.isfile(index_csv):\n",
    "        raise FileNotFoundError(f\"Missing index.csv: {index_csv}\")\n",
    "\n",
    "    df = pd.read_csv(index_csv)\n",
    "    if \"global_step\" not in df.columns or \"file\" not in df.columns:\n",
    "        raise ValueError(\"index.csv must contain columns 'global_step' and 'file'.\")\n",
    "\n",
    "    rows = df[df[\"global_step\"] == global_step]\n",
    "    if rows.empty:\n",
    "        raise ValueError(f\"No entries for global_step={global_step} in {index_csv}\")\n",
    "\n",
    "    file_paths = [os.path.join(grad_base_dir, f) for f in rows[\"file\"].tolist()]\n",
    "\n",
    "    chunks = []\n",
    "    for p in file_paths:\n",
    "        if not os.path.isfile(p):\n",
    "            warnings.warn(f\"[grad] Missing file: {p}\")\n",
    "            continue\n",
    "        t = _load_any_tensor(p)\n",
    "        g2 = _tensor_to_sampled_sq_1d(t, sample_frac)\n",
    "        chunks.append(g2)\n",
    "\n",
    "    if not chunks:\n",
    "        raise RuntimeError(\"No gradients loaded (all files missing or empty).\")\n",
    "\n",
    "    return np.concatenate(chunks, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01aff63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _param_name_passes(name: str,\n",
    "                       include_patterns: Optional[List[str]],\n",
    "                       exclude_patterns: Optional[List[str]],\n",
    "                       include_bias: bool) -> bool:\n",
    "    if not include_bias:\n",
    "        if name.endswith(\".bias\") or name.split(\".\")[-1] == \"bias\":\n",
    "            return False\n",
    "    def _match_any(patterns, s):\n",
    "        return any(re.search(p, s) for p in patterns) if patterns else False\n",
    "    if include_patterns and not _match_any(include_patterns, name):\n",
    "        return False\n",
    "    if exclude_patterns and _match_any(exclude_patterns, name):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def _gather_weight_files(ckpt_dir: str) -> List[str]:\n",
    "    safes = sorted(glob.glob(os.path.join(ckpt_dir, \"*.safetensors\")))\n",
    "    if len(safes) > 0:\n",
    "        return safes\n",
    "    pt_bin = os.path.join(ckpt_dir, \"pytorch_model.bin\")\n",
    "    if os.path.isfile(pt_bin):\n",
    "        return [pt_bin]\n",
    "    raise FileNotFoundError(f\"No weight files found in {ckpt_dir} (safetensors/bin)\")\n",
    "\n",
    "def _load_state_dict_any(ckpt_dir: str) -> dict:\n",
    "    files = _gather_weight_files(ckpt_dir)\n",
    "    state = {}\n",
    "    for f in files:\n",
    "        ext = os.path.splitext(f)[1].lower()\n",
    "        if ext == \".safetensors\":\n",
    "            if not _HAVE_SAFETENSORS:\n",
    "                raise RuntimeError(\"safetensors required; pip install safetensors\")\n",
    "            sd = safetensors_load(f, device=\"cpu\")\n",
    "            for k, v in sd.items():\n",
    "                state[k] = v.detach().to(torch.float32)\n",
    "            del sd\n",
    "        elif ext in [\".bin\", \".pt\", \".pth\"]:\n",
    "            obj = torch.load(f, map_location=\"cpu\")\n",
    "            if not isinstance(obj, dict):\n",
    "                raise RuntimeError(f\"Unexpected object in {f}: {type(obj)}\")\n",
    "            for k, v in obj.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    state[k] = v.detach().to(torch.float32)\n",
    "        else:\n",
    "            warnings.warn(f\"Skipping unsupported weight file: {f}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60f89b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_root,step,sample_frac = WEIGHT_ROOT, GLOBAL_STEP, SAMPLE_FRAC\n",
    "include_patterns=INCLUDE_PATTERNS\n",
    "exclude_patterns=EXCLUDE_PATTERNS\n",
    "include_bias=INCLUDE_BIAS\n",
    "\n",
    "pre_dir  = os.path.join(weight_root, f\"step{step:06d}_pre\")\n",
    "post_dir = os.path.join(weight_root, f\"step{step:06d}_post\")\n",
    "if not os.path.isdir(pre_dir):\n",
    "    raise FileNotFoundError(f\"Missing pre checkpoint dir: {pre_dir}\")\n",
    "if not os.path.isdir(post_dir):\n",
    "    raise FileNotFoundError(f\"Missing post checkpoint dir: {post_dir}\")\n",
    "\n",
    "sd_pre  = _load_state_dict_any(pre_dir)\n",
    "sd_post = _load_state_dict_any(post_dir)\n",
    "\n",
    "chunks = []\n",
    "missing = 0\n",
    "for name, w_pre in sd_pre.items():\n",
    "    if \".mlp.\" not in name:\n",
    "        continue\n",
    "    if not _param_name_passes(name, include_patterns, exclude_patterns, include_bias):\n",
    "        continue\n",
    "    w_post = sd_post.get(name, None)\n",
    "    if w_post is None:\n",
    "        missing += 1\n",
    "        continue\n",
    "    if w_post.shape != w_pre.shape:\n",
    "        warnings.warn(f\"Shape mismatch for {name}: pre {tuple(w_pre.shape)} vs post {tuple(w_post.shape)}\")\n",
    "        continue\n",
    "    d = (w_post - w_pre).reshape(-1)\n",
    "    if sample_frac < 1.0:\n",
    "        n = d.numel()\n",
    "        k = max(1, int(math.ceil(n * sample_frac)))\n",
    "        idx = torch.randperm(n)[:k]\n",
    "        d = d[idx]\n",
    "    d2 = (d**2).to(torch.float32).cpu().numpy()\n",
    "    chunks.append(d2)\n",
    "\n",
    "if missing > 0:\n",
    "    warnings.warn(f\"{missing} parameters present in pre but missing in post; skipped\")\n",
    "\n",
    "if not chunks:\n",
    "    raise RuntimeError(\"No delta weights computed (filters too strict or empty checkpoints).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92819593",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2_all = np.concatenate(chunks, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81d73694",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_grad_sq_from_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Gradients\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m g2_all \u001b[38;5;241m=\u001b[39m \u001b[43mload_grad_sq_from_index\u001b[49m(GRAD_BASE_DIR, GLOBAL_STEP, SAMPLE_FRAC)\n\u001b[1;32m      3\u001b[0m xg, yg, Ng \u001b[38;5;241m=\u001b[39m _make_curve(g2_all)\n\u001b[1;32m      4\u001b[0m grad_png \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(OUT_DIR, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_curve_step\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mGLOBAL_STEP\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m06d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_grad_sq_from_index' is not defined"
     ]
    }
   ],
   "source": [
    "# Gradients\n",
    "g2_all = load_grad_sq_from_index(GRAD_BASE_DIR, GLOBAL_STEP, SAMPLE_FRAC)\n",
    "xg, yg, Ng = _make_curve(g2_all)\n",
    "grad_png = os.path.join(OUT_DIR, f\"grad_curve_step{GLOBAL_STEP:06d}.png\")\n",
    "# g_cap = _plot_curve(xg, yg, f\"Gradients @ step {GLOBAL_STEP}\", grad_png, top_p=TOP_P)\n",
    "# print(f\"[DEBUG] Grad array shape: {g2_all.shape}, ndim: {g2_all.ndim}, dtype: {g2_all.dtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c787355",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[DEBUG] Î”W array shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00md2_all\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, ndim: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00md2_all\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, dtype: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00md2_all\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m xd, yd, Nd \u001b[38;5;241m=\u001b[39m _make_curve(d2_all)\n\u001b[1;32m      4\u001b[0m delta_png \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(OUT_DIR, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_delta_curve_step\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mGLOBAL_STEP\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m06d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[DEBUG] Î”W array shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00md2_all\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, ndim: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00md2_all\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, dtype: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00md2_all\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m xd, yd, Nd \u001b[38;5;241m=\u001b[39m _make_curve(d2_all)\n\u001b[1;32m      4\u001b[0m delta_png \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(OUT_DIR, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_delta_curve_step\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mGLOBAL_STEP\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m06d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:1697\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:634\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:1112\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:1090\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:494\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/cold/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2188\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2185\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2187\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2188\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2190\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2193\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/cold/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2257\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2254\u001b[0m                 queue\u001b[38;5;241m.\u001b[39mput(internal_cmd)\n\u001b[1;32m   2255\u001b[0m                 wait_timeout \u001b[38;5;241m=\u001b[39m TIMEOUT_FAST\n\u001b[0;32m-> 2257\u001b[0m         \u001b[43mnotify_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2258\u001b[0m         notify_event\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m   2260\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/cold/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/.conda/envs/cold/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(f\"[DEBUG] Î”W array shape: {d2_all.shape}, ndim: {d2_all.ndim}, dtype: {d2_all.dtype}\")\n",
    "\n",
    "xd, yd, Nd = _make_curve(d2_all)\n",
    "delta_png = os.path.join(OUT_DIR, f\"weight_delta_curve_step{GLOBAL_STEP:06d}.png\")\n",
    "d_cap = _plot_curve(xd, yd, f\"Î”W @ step {GLOBAL_STEP} (post âˆ’ pre)\", delta_png, top_p=TOP_P)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f37bba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay\n",
    "fig, ax = plt.subplots(figsize=(5.0, 4.0), dpi=200)\n",
    "ax.plot(xg, yg, linewidth=2, label=f\"Grad @ {GLOBAL_STEP}\")\n",
    "ax.plot(xd, yd, linewidth=2, linestyle=\"--\", label=f\"Î”W @ {GLOBAL_STEP}\")\n",
    "ax.set_xlabel(\"Proportion of Elements\", fontsize=12)\n",
    "ax.set_ylabel(\"Cumulative L2 Norm\\u00b2\", fontsize=12)\n",
    "ax.set_xlim(0.0, 1.0)\n",
    "ax.set_ylim(0.0, 1.0)\n",
    "ax.grid(False)\n",
    "ax.legend(loc=\"lower right\", frameon=True)\n",
    "overlay_png = os.path.join(OUT_DIR, f\"grad_vs_weight_delta_step{GLOBAL_STEP:06d}.png\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06ada1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cold",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
